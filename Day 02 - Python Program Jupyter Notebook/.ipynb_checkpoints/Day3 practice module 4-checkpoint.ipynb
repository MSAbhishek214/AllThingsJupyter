{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>NLP</th>\n",
       "      <th>am</th>\n",
       "      <th>learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I  NLP  am  learning\n",
       "0  1    0   0         0\n",
       "1  0    0   1         0\n",
       "2  0    0   0         1\n",
       "3  0    1   0         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Text = 'I am learning NLP'\n",
    "pd.get_dummies(Text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bag', 'CASE', 'Case', 'FEW', 'Few', 'This', 'Title', 'UPPER', 'WORDS', 'Words', 'a', 'and', 'by', 'corpus', 'demonstrate', 'first', 'followed', 'in', 'is', 'more', 'of', 'one', 'our', 'second', 'sentence', 'the', 'to', 'with', 'words']\n",
      "There are 29 words in vocabulary.\n",
      "There are 37 total words in vocabulary\n",
      "\n",
      "Each word frequency is as below before any sort of cleaning and pre processing\n",
      "The word (This) occurred 2 time(s) in the corpus\n",
      "The word (is) occurred 2 time(s) in the corpus\n",
      "The word (the) occurred 2 time(s) in the corpus\n",
      "The word (first) occurred 1 time(s) in the corpus\n",
      "The word (sentence) occurred 3 time(s) in the corpus\n",
      "The word (in) occurred 2 time(s) in the corpus\n",
      "The word (our) occurred 2 time(s) in the corpus\n",
      "The word (corpus) occurred 2 time(s) in the corpus\n",
      "The word (followed) occurred 1 time(s) in the corpus\n",
      "The word (by) occurred 1 time(s) in the corpus\n",
      "The word (one) occurred 1 time(s) in the corpus\n",
      "The word (more) occurred 1 time(s) in the corpus\n",
      "The word (to) occurred 1 time(s) in the corpus\n",
      "The word (demonstrate) occurred 1 time(s) in the corpus\n",
      "The word (Bag) occurred 1 time(s) in the corpus\n",
      "The word (of) occurred 1 time(s) in the corpus\n",
      "The word (words) occurred 1 time(s) in the corpus\n",
      "The word (second) occurred 1 time(s) in the corpus\n",
      "The word (with) occurred 1 time(s) in the corpus\n",
      "The word (a) occurred 1 time(s) in the corpus\n",
      "The word (FEW) occurred 1 time(s) in the corpus\n",
      "The word (UPPER) occurred 1 time(s) in the corpus\n",
      "The word (CASE) occurred 1 time(s) in the corpus\n",
      "The word (WORDS) occurred 1 time(s) in the corpus\n",
      "The word (and) occurred 1 time(s) in the corpus\n",
      "The word (Few) occurred 1 time(s) in the corpus\n",
      "The word (Title) occurred 1 time(s) in the corpus\n",
      "The word (Case) occurred 1 time(s) in the corpus\n",
      "The word (Words) occurred 1 time(s) in the corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = ['This is the first sentence in our corpus followed by one more sentence to demonstrate Bag of words',\n",
    "'This is the second sentence in our corpus with a FEW UPPER CASE WORDS and Few Title Case Words']\n",
    "\n",
    "d = {}\n",
    "vocab = []\n",
    "\n",
    "total_words = 0\n",
    "\n",
    "for doc in corpus:\n",
    "    total_words = total_words + len(doc.split())\n",
    "    for word in doc.split():\n",
    "        if word not in vocab:\n",
    "            d[word] = 1\n",
    "            vocab.append(word)\n",
    "        else:\n",
    "            d[word] = d[word] + 1\n",
    "\n",
    "vocab.sort()\n",
    "\n",
    "print(vocab)\n",
    "print('There are {} words in vocabulary.'.format(len(vocab)))\n",
    "print('There are {} total words in vocabulary\\n'.format(total_words))\n",
    "print('Each word frequency is as below before any sort of cleaning and pre processing')\n",
    "for key, value in d.items():\n",
    "    print('The word ({}) occurred {} time(s) in the corpus'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 2 0]\n",
      " [1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text = ['I love NLP NLP', 'I will learn NLP in 2 months']\n",
    "vectorizer = CountVectorizer(ngram_range=())\n",
    "vectorizer.fit(text)\n",
    "vector = vectorizer.transform(text)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       good       job      miss\n",
      "0  0.385372  0.652491  0.652491\n",
      "1  1.000000  0.000000  0.000000\n",
      "\n",
      "with smoothing\n",
      "       good       job      miss\n",
      "0  0.449436  0.631667  0.631667\n",
      "1  1.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sent1 = 'This is a good job. I will not miss it for anything'\n",
    "sent2 = 'This is not good at all'\n",
    "\n",
    "tfid_vec = TfidfVectorizer(use_idf=True, smooth_idf=False, ngram_range=(1,1), stop_words='english')\n",
    "tfid_data = tfid_vec.fit_transform([sent1, sent2])\n",
    "\n",
    "tfid_dataframe = pd.DataFrame(tfid_data.toarray(), columns=tfid_vec.get_feature_names())\n",
    "print(tfid_dataframe)\n",
    "print()\n",
    "\n",
    "tf_idf_vec_smooth = TfidfVectorizer(use_idf=True, smooth_idf=True, ngram_range=(1,1), stop_words='english')\n",
    "tfid_data_smooth = tf_idf_vec_smooth.fit_transform([sent1, sent2])\n",
    "\n",
    "print('with smoothing')\n",
    "tfid_dataframe_smooth = pd.DataFrame(tfid_data_smooth.toarray(), columns=tf_idf_vec_smooth.get_feature_names())\n",
    "print(tfid_dataframe_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "article = scrapped_data.read()\n",
    "parsed_article = bs.BeautifulSoup(article, 'lxml')\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "article_text = ''\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_article = article_text.lower()\n",
    "processed_article = re.sub('[^a-z]', ' ', processed_article)\n",
    "processed_article = re.sub(r'\\s', ' ', processed_article)\n",
    "\n",
    "all_sentences = nltk.sent_tokenize(processed_article)\n",
    "\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b941c0bd65be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtfid_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtfidf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tfid' is not defined"
     ]
    }
   ],
   "source": [
    "documents = (\n",
    "\"I like NLP\",\n",
    "\"I am exploring NLP\",\n",
    "\"I am a beginner in NLP\",\n",
    "\"I want to learn NLP\",\n",
    "\"I like advanced NLP\"\n",
    ")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tfid_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "\n",
    "# Initialize recognizer class (for recognizing the speech)\n",
    "r = sr.Recognizer()\n",
    "\n",
    "\n",
    "\n",
    "# Reading Audio file as source\n",
    "# listening the audio file and store in audio_text variable\n",
    "\n",
    "\n",
    "\n",
    "with sr.AudioFile('male.wav') as source:\n",
    "\n",
    "    audio_text = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please say something\n",
      "Time over, thanks\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r=sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Please say something\")\n",
    "    audio = r.listen(source)\n",
    "    print(\"Time over, thanks\")\n",
    "\n",
    "try:\n",
    "    print(\"I think you said: \"+r.recognize_google(audio));\n",
    "except:\n",
    "    pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.6833333333333332, subjectivity=0.7555555555555555)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"I like this phone. screen quality and camera clarity is really good.\"\n",
    "review2 = \"This tv is not good. Bad quality, no clarity, worst experience\"\n",
    "\n",
    "#import libraries\n",
    "from textblob import TextBlob\n",
    "\n",
    "#TextBlob has a pre trained sentiment prediction model\n",
    "blob = TextBlob(review)\n",
    "blob.sentiment\n",
    "\n",
    "#now lets look at the sentiment of review2\n",
    "blob = TextBlob(review2)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
